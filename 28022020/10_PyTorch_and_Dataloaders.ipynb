{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)",
      "language": "python",
      "name": "python37464bitanaconda3virtualenv32645142025941c89ba0a8870ffeabe0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4-final"
    },
    "colab": {
      "name": "10_PyTorch_and_Dataloaders.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "5LM_-Vcvky2g"
      },
      "outputs": [],
      "source": [
        "## 10: PyTorch practice, hints and Dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "mmnSmS4Gky2q"
      },
      "outputs": [],
      "source": [
        "Credits:\n",
        "* First part is based on YSDA [Practical RL course week04 materials](https://github.com/yandexdataschool/Practical_RL/tree/master/week04_%5Brecap%5D_deep_learning).\n",
        "* Second part is based on PyTorch official tutorials and [this kaggle kernel](https://www.kaggle.com/pinocookie/pytorch-dataset-and-dataloader)\n",
        "* Third part is based on PyTorch tutorial by [Stanford CS 231n course](http://cs231n.stanford.edu)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "C-bSFh21ky2x"
      },
      "outputs": [],
      "source": [
        "![img](https://pytorch.org/tutorials/_static/pytorch-logo-dark.svg)\n",
        "\n",
        "__This notebook__ will teach you to use pytorch low-level core. You can install it [here](http://pytorch.org/).\n",
        "\n",
        "__Pytorch feels__ differently than other frameworks (like tensorflow/theano) on almost every level. TensorFlow makes your code live in two \"worlds\" simultaneously:  symbolic graphs and actual tensors. First you declare a symbolic \"recipe\" of how to get from inputs to outputs, then feed it with actual minibatches of data.  In pytorch, __there's only one world__: all tensors have a numeric value.\n",
        "\n",
        "You compute outputs on the fly without pre-declaring anything. The code looks exactly as in pure numpy with one exception: pytorch computes gradients for you. And can run stuff on GPU. And has a number of pre-implemented building blocks for your neural nets. [And a few more things.](https://medium.com/towards-data-science/pytorch-vs-tensorflow-spotting-the-difference-25c75777377b)\n",
        "\n",
        "Let's dive into it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "rt1MT_dvky3K"
      },
      "outputs": [],
      "source": [
        "### Task 1: Tensormancy\n",
        "\n",
        "__1.1 The [_disclaimer_](https://gist.githubusercontent.com/justheuristic/e2c1fa28ca02670cabc42cacf3902796/raw/fd3d935cef63a01b85ed2790b5c11c370245cbd7/stddisclaimer.h)__\n",
        "\n",
        "Let's write another function, this time in polar coordinates:\n",
        "$$\\rho(\\theta) = (1 + 0.9 \\cdot cos (6 \\cdot \\theta) ) \\cdot (1 + 0.01 \\cdot cos(24 \\cdot \\theta)) \\cdot (0.5 + 0.05 \\cdot cos(200 \\cdot \\theta)) \\cdot (10 + sin(10 \\cdot \\theta))$$\n",
        "\n",
        "\n",
        "Then convert it into cartesian coordinates ([howto](http://www.mathsisfun.com/polar-cartesian-coordinates.html)) and plot the results.\n",
        "\n",
        "Use torch tensors only: no lists, loops, numpy arrays, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"357.238125pt\" version=\"1.1\" viewBox=\"0 0 386.845313 357.238125\" width=\"386.845313pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 357.238125 \nL 386.845313 357.238125 \nL 386.845313 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 44.845313 333.36 \nL 379.645313 333.36 \nL 379.645313 7.2 \nL 44.845313 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 62.927241 170.788546 \nL 71.585558 171.713659 \nL 86.38179 172.446027 \nL 85.848986 173.285346 \nL 69.886337 174.534021 \nL 60.063494 175.791052 \nL 69.708663 176.41519 \nL 85.33943 176.640739 \nL 85.362121 177.476908 \nL 70.055395 179.213174 \nL 61.117451 180.734708 \nL 71.503221 180.986823 \nL 87.550031 180.660308 \nL 88.095508 181.440186 \nL 73.777334 183.573079 \nL 65.872344 185.266387 \nL 76.665827 185.108916 \nL 92.674537 184.230608 \nL 93.658503 184.912033 \nL 80.566488 187.332458 \nL 73.768296 189.102779 \nL 84.649002 188.53151 \nL 100.223144 187.140296 \nL 101.574742 187.689832 \nL 89.908727 190.273923 \nL 84.284003 192.022897 \nL 94.995693 191.056379 \nL 109.8214 189.217364 \nL 111.505798 189.603469 \nL 101.458804 192.21 \nL 97.07671 193.83305 \nL 107.401614 192.508451 \nL 121.209525 190.309689 \nL 123.196573 190.503855 \nL 114.920106 192.981534 \nL 111.80263 194.378153 \nL 121.508282 192.759172 \nL 134.02872 190.31775 \nL 136.241634 190.307373 \nL 129.774493 192.519034 \nL 127.83446 193.616694 \nL 136.655349 191.803171 \nL 147.625716 189.266207 \nL 149.92154 189.068735 \nL 145.146392 190.921091 \nL 144.17429 191.696619 \nL 151.858933 189.818261 \nL 161.083961 187.346587 \nL 163.287178 187.010237 \nL 159.951097 188.470459 \nL 159.666183 188.951999 \nL 166.051579 187.143488 \nL 173.472076 184.88026 \nL 175.43203 184.469172 \nL 173.219112 185.558024 \nL 173.347321 185.806551 \nL 178.407365 184.17678 \nL 184.120259 182.219963 \nL 185.751345 181.794047 \nL 184.35627 182.564576 \nL 184.684721 182.649417 \nL 188.520145 181.263907 \nL 192.739566 179.657744 \nL 194.020779 179.261537 \nL 193.18518 179.780166 \nL 193.568135 179.765626 \nL 196.351937 178.649897 \nL 199.342283 177.39568 \nL 200.288535 177.060511 \nL 199.796109 177.401744 \nL 200.127389 177.349415 \nL 202.047404 176.504413 \nL 204.067859 175.578583 \nL 204.696209 175.333598 \nL 204.347607 175.587144 \nL 204.529317 175.566611 \nL 205.756354 174.982558 \nL 207.038277 174.348734 \nL 207.350192 174.230669 \nL 206.943106 174.51161 \nL 206.870451 174.609109 \nL 207.556476 174.269185 \nL 208.308947 173.878868 \nL 208.290865 173.93511 \nL 207.616349 174.388894 \nL 207.180893 174.708205 \nL 207.472599 174.583141 \nL 207.897449 174.369281 \nL 207.530543 174.655018 \nL 206.381386 175.455569 \nL 205.482298 176.112884 \nL 205.532446 176.153692 \nL 205.832483 176.025079 \nL 205.100625 176.599378 \nL 203.280795 177.944666 \nL 201.831895 179.0637 \nL 201.800125 179.198784 \nL 202.177293 179.039327 \nL 201.068342 179.96418 \nL 198.397436 182.073489 \nL 196.328503 183.783225 \nL 196.377345 183.91852 \nL 197.028262 183.588578 \nL 195.535265 184.927726 \nL 191.85452 188.036853 \nL 189.117244 190.465147 \nL 189.414268 190.47974 \nL 190.532741 189.81228 \nL 188.665193 191.621116 \nL 183.859721 195.962106 \nL 180.449524 199.213497 \nL 181.177643 198.9464 \nL 182.961203 197.737711 \nL 180.767498 200.039155 \nL 174.807135 205.796056 \nL 170.795613 209.912064 \nL 172.156443 209.150276 \nL 174.79874 207.159924 \nL 172.383933 209.916407 \nL 165.362049 217.168848 \nL 160.913839 222.091083 \nL 163.101806 220.582778 \nL 166.757521 217.56115 \nL 164.273944 220.666321 \nL 156.409507 229.355587 \nL 151.757355 234.923847 \nL 154.904586 232.428951 \nL 159.635543 228.175671 \nL 157.241153 231.482392 \nL 148.828953 241.430256 \nL 144.210123 247.42963 \nL 148.333009 243.788798 \nL 154.070357 238.214556 \nL 151.877465 241.588615 \nL 143.20964 252.564124 \nL 138.800301 258.796944 \nL 143.786471 253.977172 \nL 150.342837 247.125934 \nL 148.393282 250.488593 \nL 139.700071 262.279304 \nL 135.590217 268.613127 \nL 141.242008 262.694375 \nL 148.371469 254.707459 \nL 146.652946 258.0372 \nL 138.093702 270.477781 \nL 134.313218 276.837797 \nL 140.419022 269.950242 \nL 147.886068 260.998663 \nL 146.373314 264.293744 \nL 138.069677 277.239479 \nL 134.635442 283.561077 \nL 141.019334 275.824429 \nL 148.637375 266.055955 \nL 147.324162 269.291714 \nL 139.395052 282.57405 \nL 136.33923 288.761923 \nL 142.867658 280.265587 \nL 150.491293 269.802981 \nL 149.39043 272.922485 \nL 141.960007 286.329832 \nL 139.321882 292.260041 \nL 145.875791 283.094432 \nL 153.372694 272.069493 \nL 152.495792 275.007373 \nL 145.670506 288.31406 \nL 143.469127 293.874539 \nL 149.919614 284.172093 \nL 157.152663 272.758127 \nL 156.488884 275.478558 \nL 150.330008 288.496835 \nL 148.544536 293.631949 \nL 154.754517 283.57737 \nL 161.589522 271.987222 \nL 161.101953 274.504207 \nL 155.616167 287.121725 \nL 154.191277 291.844152 \nL 160.038468 281.644589 \nL 166.369341 270.090566 \nL 166.01088 272.453126 \nL 161.165972 284.628507 \nL 160.03746 288.987719 \nL 165.441409 278.817845 \nL 171.210948 267.461205 \nL 170.947255 269.711389 \nL 166.703938 281.423749 \nL 165.826471 285.449554 \nL 170.759229 275.407652 \nL 175.961503 264.32772 \nL 175.785666 266.455833 \nL 172.126072 277.633899 \nL 171.488311 281.281698 \nL 175.961605 271.38521 \nL 180.621951 260.592905 \nL 180.553712 262.511854 \nL 177.48942 272.983359 \nL 177.105202 276.120503 \nL 181.140449 266.351875 \nL 185.284745 255.845845 \nL 185.351804 257.409496 \nL 182.906793 266.90574 \nL 182.788354 269.353335 \nL 186.386415 259.738841 \nL 190.017213 249.577252 \nL 190.229669 250.640388 \nL 188.407811 258.866446 \nL 188.537408 260.482066 \nL 191.668055 251.156167 \nL 194.761128 241.504807 \nL 195.095982 241.991553 \nL 193.854092 248.730069 \nL 194.172742 249.485596 \nL 196.790057 240.698686 \nL 199.315416 231.814382 \nL 199.719952 231.757506 \nL 198.964828 236.944526 \nL 199.385656 236.9503 \nL 201.459407 229.005609 \nL 203.41085 221.16183 \nL 203.822331 220.687296 \nL 203.430766 224.42443 \nL 203.866609 223.887542 \nL 205.40785 217.044236 \nL 206.821435 210.44248 \nL 207.188165 209.718129 \nL 207.035922 212.223611 \nL 207.421958 211.378572 \nL 208.487505 205.780359 \nL 209.439148 200.498349 \nL 209.731208 199.68483 \nL 209.713663 201.233018 \nL 210.015033 200.291342 \nL 210.692854 195.954033 \nL 211.28101 191.949677 \nL 211.489279 191.182899 \nL 211.529421 192.068696 \nL 211.7371 191.20818 \nL 212.126432 188.04942 \nL 212.453201 185.197486 \nL 212.584166 184.596358 \nL 212.6338 185.125969 \nL 212.758304 184.500133 \nL 212.954887 182.374192 \nL 213.113791 180.497505 \nL 213.186241 180.171189 \nL 213.226404 180.654824 \nL 213.2939 180.393828 \nL 213.381583 179.106052 \nL 213.450772 177.988014 \nL 213.494057 178.028767 \nL 213.534693 178.75899 \nL 213.583383 178.955769 \nL 213.627752 178.268181 \nL 213.66487 177.660676 \nL 213.715902 178.131748 \nL 213.792158 179.357983 \nL 213.866586 180.059028 \nL 213.909616 179.707968 \nL 213.948191 179.352083 \nL 214.047282 180.289094 \nL 214.213219 182.211433 \nL 214.358752 183.429689 \nL 214.417338 183.159075 \nL 214.467326 182.816492 \nL 214.656197 184.247352 \nL 214.980583 187.037686 \nL 215.242135 188.782501 \nL 215.311937 188.373181 \nL 215.364723 187.848462 \nL 215.688782 189.817892 \nL 216.256167 193.651343 \nL 216.681619 195.952699 \nL 216.742777 195.226487 \nL 216.776665 194.363872 \nL 217.289369 196.942404 \nL 218.204117 202.012834 \nL 218.847711 204.919315 \nL 218.866774 203.715054 \nL 218.848023 202.371848 \nL 219.612175 205.639566 \nL 220.998832 212.142221 \nL 221.918758 215.691603 \nL 221.844181 213.830852 \nL 221.722574 211.848132 \nL 222.804825 215.860876 \nL 224.799328 223.947886 \nL 226.047506 228.12776 \nL 225.80246 225.398132 \nL 225.505595 222.590759 \nL 226.965459 227.349488 \nL 229.697897 237.083045 \nL 231.306648 241.808207 \nL 230.786637 237.980173 \nL 230.220181 234.159189 \nL 232.099618 239.601813 \nL 235.676877 250.936096 \nL 237.651443 256.061157 \nL 236.733222 250.935532 \nL 235.791176 245.951965 \nL 238.112369 251.976474 \nL 242.609993 264.778529 \nL 244.932748 270.139828 \nL 243.491894 263.595367 \nL 242.072908 257.377692 \nL 244.84405 263.87569 \nL 250.310154 277.969675 \nL 252.950589 283.421169 \nL 250.876174 275.427823 \nL 248.894346 267.983499 \nL 252.114624 274.854689 \nL 258.571233 290.039208 \nL 261.487793 295.45019 \nL 258.682506 286.037522 \nL 256.063965 277.417015 \nL 259.71334 284.540793 \nL 267.140333 300.558767 \nL 270.262961 305.768602 \nL 266.631795 294.982044 \nL 263.302888 285.239974 \nL 267.317006 292.428108 \nL 275.614943 308.9061 \nL 278.819058 313.68242 \nL 274.266421 301.577592 \nL 270.154686 290.778964 \nL 274.403049 297.756897 \nL 283.360505 314.181038 \nL 286.461109 318.237456 \nL 280.919417 304.940773 \nL 275.981793 293.218176 \nL 280.274942 299.670305 \nL 289.576659 315.450363 \nL 292.363853 318.534545 \nL 285.84656 304.322693 \nL 280.118611 291.947229 \nL 284.255225 297.616002 \nL 293.543542 312.220068 \nL 295.848411 314.220083 \nL 288.495608 299.551167 \nL 282.123212 286.9412 \nL 285.949771 291.709264 \nL 294.912624 304.793955 \nL 296.66474 305.788752 \nL 288.737557 291.231839 \nL 281.963077 278.879564 \nL 285.411488 282.786866 \nL 293.844211 294.241823 \nL 295.078959 294.454985 \nL 286.897713 280.553251 \nL 279.998072 268.900502 \nL 283.075863 272.085124 \nL 290.885231 281.978904 \nL 291.699124 281.672163 \nL 283.557406 268.816313 \nL 276.771791 258.157134 \nL 279.518048 260.768672 \nL 286.675508 269.242594 \nL 287.163856 268.620848 \nL 279.271294 257.004754 \nL 272.758527 247.461759 \nL 275.198669 249.601385 \nL 281.685451 256.785543 \nL 281.903464 255.962684 \nL 274.381073 245.62372 \nL 268.225025 237.19559 \nL 270.352488 238.908061 \nL 276.131175 244.893257 \nL 276.094117 243.916064 \nL 269.010596 234.815242 \nL 263.255815 227.448088 \nL 265.044265 228.75091 \nL 270.064842 233.606846 \nL 269.776229 232.503078 \nL 263.189917 224.589212 \nL 257.876439 218.226965 \nL 259.303691 219.142829 \nL 263.529288 222.950301 \nL 263.008139 221.760927 \nL 256.988014 214.994238 \nL 252.165621 209.592907 \nL 253.232253 210.166545 \nL 256.661248 213.035623 \nL 255.952617 211.82047 \nL 250.572142 206.162335 \nL 246.29351 201.679375 \nL 247.026638 201.974738 \nL 249.697901 204.041216 \nL 248.865366 202.865693 \nL 244.183602 198.259654 \nL 240.487442 194.637488 \nL 240.932142 194.72447 \nL 242.916758 196.134814 \nL 242.027608 195.054187 \nL 238.073264 191.415786 \nL 234.97347 188.575861 \nL 235.183591 188.520212 \nL 236.573997 189.418269 \nL 235.69162 188.472565 \nL 232.462327 185.695514 \nL 229.949939 183.545182 \nL 229.988831 183.408825 \nL 230.900521 183.935366 \nL 230.09081 183.156485 \nL 227.563636 181.126302 \nL 225.618535 179.571373 \nL 225.572073 179.421099 \nL 226.159808 179.722825 \nL 225.506161 179.145161 \nL 223.645732 177.747327 \nL 222.242847 176.697055 \nL 222.233261 176.610002 \nL 222.707722 176.844621 \nL 222.315669 176.504777 \nL 221.064432 175.618876 \nL 220.164045 174.979124 \nL 220.34827 175.03567 \nL 220.971984 175.360914 \nL 220.951543 175.283337 \nL 220.204621 174.770515 \nL 219.730165 174.432304 \nL 220.276922 174.698029 \nL 221.332846 175.247263 \nL 221.766466 175.426776 \nL 221.351827 175.12651 \nL 221.174507 174.963977 \nL 222.233842 175.47364 \nL 223.983938 176.334078 \nL 224.903604 176.730803 \nL 224.588649 176.475765 \nL 224.535501 176.359435 \nL 226.221536 177.114142 \nL 228.881068 178.321351 \nL 230.270476 178.872007 \nL 229.794062 178.512993 \nL 229.675284 178.32971 \nL 232.068961 179.305857 \nL 235.80406 180.852668 \nL 237.616777 181.487145 \nL 236.723048 180.911309 \nL 236.357292 180.576941 \nL 239.514267 181.735507 \nL 244.445744 183.582435 \nL 246.616762 184.232926 \nL 245.070284 183.36745 \nL 244.292254 182.827399 \nL 248.23891 184.116395 \nL 254.432761 186.195379 \nL 256.872897 186.796645 \nL 254.458984 185.604594 \nL 253.11653 184.829595 \nL 257.835294 186.183448 \nL 265.283474 188.399759 \nL 267.872515 188.89025 \nL 264.405544 187.369744 \nL 262.366669 186.355946 \nL 267.791511 187.70061 \nL 276.409188 189.942871 \nL 279.011398 190.273637 \nL 274.363119 188.461554 \nL 271.541372 187.234501 \nL 277.581451 188.500476 \nL 287.24128 190.659995 \nL 289.746466 190.806624 \nL 283.878384 188.777786 \nL 280.260275 187.391725 \nL 286.845532 188.526977 \nL 297.439813 190.516211 \nL 299.80569 190.482722 \nL 292.772879 188.336202 \nL 288.421969 186.862916 \nL 295.544454 187.836151 \nL 307.038947 189.593861 \nL 309.300442 189.402395 \nL 301.212939 187.239389 \nL 296.234984 185.749349 \nL 303.953711 186.54011 \nL 316.397364 188.02054 \nL 318.632153 187.69332 \nL 309.584676 185.597498 \nL 304.068845 184.144599 \nL 312.470786 184.727714 \nL 325.94638 185.881892 \nL 328.206377 185.426587 \nL 318.214429 183.459062 \nL 312.179236 182.077521 \nL 321.308296 182.412595 \nL 335.841079 183.175802 \nL 338.084484 182.584553 \nL 327.064271 180.795309 \nL 320.438873 179.510173 \nL 330.224862 179.544418 \nL 345.690886 179.840316 \nL 347.752384 179.103829 \nL 335.564638 177.551151 \nL 328.222385 176.395238 \nL 338.448788 176.08011 \nL 354.533071 175.841918 \nL 356.157496 174.970249 \nL 342.704403 173.733806 \nL 334.54015 172.759145 \nL 344.874563 172.071852 \nL 361.111434 171.269208 \nL 362.042177 170.304879 \nL 347.371895 169.480859 \nL 338.388924 168.755277 \nL 348.469763 167.711817 \nL 364.350129 166.366601 \nL 364.427131 165.38047 \nL 348.787489 165.058885 \nL 339.138155 164.648047 \nL 348.663799 163.299797 \nL 363.750178 161.481864 \nL 362.958969 160.553701 \nL 346.760197 160.79155 \nL 336.715987 160.738521 \nL 345.486996 159.157438 \nL 359.46636 156.966882 \nL 357.905624 156.16591 \nL 341.61481 156.973572 \nL 331.482015 157.289729 \nL 339.374958 155.555851 \nL 352.030308 153.108369 \nL 349.831209 152.48718 \nL 333.868506 153.833533 \nL 323.909614 154.504313 \nL 330.81964 152.704358 \nL 341.967736 150.128977 \nL 339.233396 149.729611 \nL 323.935626 151.55461 \nL 314.348212 152.549553 \nL 320.161159 150.781029 \nL 329.627266 148.222304 \nL 326.439301 148.080001 \nL 312.09551 150.298932 \nL 303.048469 151.573143 \nL 307.67109 149.94013 \nL 315.331443 147.548648 \nL 311.803695 147.682232 \nL 298.703752 150.179484 \nL 290.383413 151.665105 \nL 293.806595 150.259048 \nL 299.65999 148.165306 \nL 295.981084 148.55967 \nL 284.415422 151.185643 \nL 277.024922 152.786942 \nL 279.358607 151.6633 \nL 283.563395 149.948094 \nL 279.979234 150.54601 \nL 270.177139 153.132388 \nL 263.887815 154.735865 \nL 265.340105 153.902526 \nL 268.180739 152.584103 \nL 264.926768 153.298823 \nL 256.981651 155.690553 \nL 251.873271 157.188944 \nL 252.687576 156.614396 \nL 254.495351 155.659407 \nL 251.729902 156.400834 \nL 245.569328 158.487016 \nL 241.605811 159.802458 \nL 242.000747 159.435445 \nL 243.081252 158.782574 \nL 240.863044 159.479274 \nL 236.282407 161.205312 \nL 233.336565 162.297796 \nL 233.481555 162.083078 \nL 234.084826 161.661429 \nL 232.398535 162.266009 \nL 229.130284 163.624361 \nL 227.035047 164.483751 \nL 227.06198 164.364975 \nL 227.394167 164.097399 \nL 226.195133 164.577288 \nL 223.969866 165.588866 \nL 222.563012 166.21987 \nL 222.592763 166.131607 \nL 222.843795 165.926371 \nL 222.091755 166.250738 \nL 220.665753 166.951538 \nL 219.808505 167.36327 \nL 219.969591 167.221226 \nL 220.33228 166.962015 \nL 220.000065 167.095453 \nL 219.151787 167.535027 \nL 218.724843 167.739557 \nL 219.156205 167.435932 \nL 219.827735 166.978181 \nL 219.89224 166.883271 \nL 219.40669 167.131505 \nL 219.297725 167.148628 \nL 220.140369 166.553897 \nL 221.312597 165.728026 \nL 221.742987 165.371946 \nL 221.401862 165.525852 \nL 221.497921 165.38761 \nL 222.886211 164.3544 \nL 224.736639 162.970747 \nL 225.490205 162.329506 \nL 225.073279 162.514804 \nL 225.261615 162.26594 \nL 227.31968 160.63105 \nL 230.007906 158.482699 \nL 231.031779 157.542176 \nL 230.322051 157.91215 \nL 230.492058 157.609711 \nL 233.329997 155.196937 \nL 236.990881 152.06588 \nL 238.217793 150.827571 \nL 237.000062 151.566618 \nL 237.037521 151.285843 \nL 240.73368 147.921653 \nL 245.453584 143.601509 \nL 246.78534 142.100957 \nL 244.840103 143.433898 \nL 244.614815 143.28262 \nL 249.182496 138.831554 \nL 254.958235 133.173927 \nL 256.247536 131.507337 \nL 253.357992 133.700493 \nL 252.721459 133.829593 \nL 258.076623 128.240341 \nL 264.782327 121.208113 \nL 265.83819 119.544109 \nL 261.826473 122.877717 \nL 260.636314 123.467465 \nL 266.5965 116.799834 \nL 273.990961 108.492284 \nL 274.62149 107.045366 \nL 269.407436 111.75134 \nL 267.573649 112.967206 \nL 273.900551 105.374591 \nL 281.686152 95.996667 \nL 281.760901 94.964813 \nL 275.405356 101.158897 \nL 272.930109 103.096671 \nL 279.396168 94.767677 \nL 287.297911 84.557023 \nL 286.788397 84.060019 \nL 279.485835 91.711936 \nL 276.464785 94.369837 \nL 282.902429 85.466651 \nL 290.719004 74.626122 \nL 289.686424 74.689999 \nL 281.703861 83.656462 \nL 278.284497 86.956781 \nL 284.588202 77.595094 \nL 292.18978 66.274856 \nL 290.735202 66.866991 \nL 282.334874 76.965 \nL 278.661196 80.807981 \nL 284.75528 71.082882 \nL 292.043841 59.415708 \nL 290.255851 60.503358 \nL 281.650639 71.569126 \nL 277.829995 75.878837 \nL 283.634809 65.908193 \nL 290.510778 54.053126 \nL 288.446245 55.636892 \nL 279.803493 67.533035 \nL 275.912795 72.259776 \nL 281.339298 62.199881 \nL 287.697654 50.356941 \nL 285.402824 52.449978 \nL 276.874056 65.030327 \nL 272.982787 70.123153 \nL 277.951963 60.145854 \nL 283.709217 48.518888 \nL 281.24616 51.104974 \nL 272.988123 64.177469 \nL 269.176846 69.550809 \nL 273.645086 59.797501 \nL 278.765169 48.541717 \nL 276.220931 51.546752 \nL 268.387627 64.874823 \nL 264.744572 70.402695 \nL 268.712893 60.950685 \nL 273.210879 50.143441 \nL 270.681614 53.446594 \nL 263.3982 66.789415 \nL 259.998979 72.334109 \nL 263.498505 63.202596 \nL 267.420506 52.857562 \nL 264.98406 56.336609 \nL 258.322353 69.505919 \nL 255.209848 74.962187 \nL 258.274895 66.155098 \nL 261.665249 56.279056 \nL 259.360789 59.864 \nL 253.336186 72.75752 \nL 250.513666 78.087522 \nL 253.157205 69.655324 \nL 256.033886 60.315888 \nL 253.86183 64.017735 \nL 248.453097 76.608327 \nL 245.896357 81.842754 \nL 248.103711 73.925849 \nL 250.455224 65.293053 \nL 248.39797 69.185873 \nL 243.581051 81.460785 \nL 241.26285 86.660326 \nL 243.007211 79.485038 \nL 244.814649 71.811336 \nL 242.866592 75.967975 \nL 238.64158 87.849798 \nL 236.555123 93.040879 \nL 237.826876 86.857166 \nL 239.096567 80.398438 \nL 237.284365 84.812762 \nL 233.679861 96.106357 \nL 231.846178 101.228908 \nL 232.676477 96.220919 \nL 233.462402 91.136433 \nL 231.84182 95.680724 \nL 228.892815 106.088874 \nL 227.347781 110.990246 \nL 227.811503 107.209154 \nL 228.212436 103.499721 \nL 226.844139 107.948204 \nL 224.559142 117.152957 \nL 223.329342 121.635723 \nL 223.526962 118.991397 \nL 223.662092 116.508036 \nL 222.583829 120.610605 \nL 220.923204 128.374359 \nL 220.007396 132.266368 \nL 220.039414 130.571185 \nL 220.020121 129.074453 \nL 219.232512 132.633571 \nL 218.110281 138.860693 \nL 217.47746 142.059434 \nL 217.426289 141.084325 \nL 217.339367 140.303423 \nL 216.810657 143.204611 \nL 216.113768 147.940535 \nL 215.712726 150.418859 \nL 215.636713 149.923514 \nL 215.540169 149.585566 \nL 215.219405 151.786383 \nL 214.829689 155.178084 \nL 214.601526 156.959783 \nL 214.535011 156.698076 \nL 214.459483 156.530978 \nL 214.287904 158.037296 \nL 214.096984 160.296607 \nL 213.982941 161.4361 \nL 213.936591 161.158597 \nL 213.886396 160.896794 \nL 213.804157 161.754188 \nL 213.721905 163.1411 \nL 213.667555 163.719813 \nL 213.62865 163.190524 \nL 213.583421 162.59562 \nL 213.535033 162.892963 \nL 213.495728 163.705703 \nL 213.454838 163.832707 \nL 213.390231 162.850873 \nL 213.309742 161.732516 \nL 213.249953 161.596627 \nL 213.216682 162.148309 \nL 213.154699 161.94836 \nL 213.016118 160.354404 \nL 212.846749 158.56928 \nL 212.744183 158.139866 \nL 212.708711 158.723464 \nL 212.603089 158.311815 \nL 212.330723 155.968804 \nL 212.008855 153.394874 \nL 211.844555 152.793238 \nL 211.822209 153.655952 \nL 211.658589 153.116586 \nL 211.179889 149.8816 \nL 210.629941 146.387571 \nL 210.392542 145.702309 \nL 210.41632 147.048168 \nL 210.183682 146.432369 \nL 209.409234 142.141486 \nL 208.539827 137.577729 \nL 208.222843 136.879165 \nL 208.342107 138.897087 \nL 208.031615 138.244563 \nL 206.854033 132.727623 \nL 205.558898 126.949283 \nL 205.164443 126.322922 \nL 205.449551 129.218866 \nL 205.05915 128.587524 \nL 203.360083 121.707619 \nL 201.52814 114.619671 \nL 201.076072 114.195184 \nL 201.624034 118.200928 \nL 201.166197 117.685632 \nL 198.831309 109.382389 \nL 196.363312 100.978478 \nL 195.898825 100.929936 \nL 196.832624 106.278614 \nL 196.338086 106.000927 \nL 193.272309 96.307378 \nL 190.095772 86.678558 \nL 189.688381 87.193019 \nL 191.144599 94.066747 \nL 190.658112 94.143709 \nL 186.793305 83.169653 \nL 182.865696 72.471436 \nL 182.596783 73.699651 \nL 184.706936 82.18816 \nL 184.27594 82.697777 \nL 179.567626 70.590637 \nL 174.870239 59.000933 \nL 174.819794 61.032547 \nL 177.69638 71.127504 \nL 177.363672 72.103631 \nL 171.788365 59.029466 \nL 166.324338 46.73683 \nL 166.569781 49.619089 \nL 170.307837 61.252188 \nL 170.117933 62.715801 \nL 163.686277 48.88534 \nL 157.499035 36.12883 \nL 158.129888 39.913356 \nL 162.81676 52.996194 \nL 162.833022 54.996124 \nL 155.62332 40.72215 \nL 148.83092 27.846051 \nL 149.962362 32.610978 \nL 155.675045 47.030169 \nL 155.988645 49.647897 \nL 148.177978 35.371716 \nL 140.996568 22.833416 \nL 142.756688 28.642535 \nL 149.52763 44.194005 \nL 150.239585 47.493662 \nL 142.100827 33.734614 \nL 134.82404 22.025455 \nL 137.305487 28.838282 \nL 145.070221 45.156525 \nL 146.246915 49.108189 \nL 138.095328 36.342245 \nL 131.027297 25.857092 \nL 134.229486 33.460452 \nL 142.792181 50.011556 \nL 144.422513 54.449401 \nL 136.537567 42.9907 \nL 129.912149 33.922831 \nL 133.716813 41.947326 \nL 142.770647 58.120282 \nL 144.757825 62.774545 \nL 137.323849 52.727588 \nL 131.26144 45.058821 \nL 135.465718 53.08149 \nL 144.664374 68.330597 \nL 146.862554 72.917282 \nL 139.962941 64.223353 \nL 134.486401 57.803155 \nL 138.872926 65.470272 \nL 147.916334 79.430573 \nL 150.187037 83.738648 \nL 143.844498 76.270388 \nL 138.935132 70.923571 \nL 143.334847 78.021763 \nL 152.01821 90.535217 \nL 154.271579 94.463748 \nL 148.501046 88.106532 \nL 144.149006 83.700731 \nL 148.464853 90.153184 \nL 156.672431 101.21236 \nL 158.869652 104.745872 \nL 153.705161 99.423801 \nL 149.928672 95.878763 \nL 154.111743 101.683672 \nL 161.776428 111.348646 \nL 163.908782 114.511448 \nL 159.398886 110.170856 \nL 156.227967 107.426743 \nL 160.24101 112.598851 \nL 167.303369 120.936482 \nL 169.36242 123.750807 \nL 165.546937 120.33001 \nL 162.995887 118.313907 \nL 166.788188 122.85542 \nL 173.180533 129.922326 \nL 175.142624 132.393773 \nL 172.030623 129.803763 \nL 170.080225 128.416629 \nL 173.586302 132.320582 \nL 179.240815 138.174792 \nL 181.069529 140.29969 \nL 178.632718 138.425737 \nL 177.229776 137.549926 \nL 180.384007 140.817531 \nL 185.252867 145.537541 \nL 186.910885 147.316758 \nL 185.09048 146.031954 \nL 184.160002 145.547978 \nL 186.912873 148.201878 \nL 190.981586 151.893566 \nL 192.440211 153.339931 \nL 191.157353 152.518251 \nL 190.612131 152.314835 \nL 192.93468 154.398192 \nL 196.220894 157.1869 \nL 197.458282 158.321278 \nL 196.613353 157.838832 \nL 196.35019 157.810244 \nL 198.224831 159.375265 \nL 200.766715 161.391582 \nL 201.756305 162.232937 \nL 201.214195 161.959696 \nL 201.097467 161.995709 \nL 202.506498 163.093987 \nL 204.357087 164.467664 \nL 205.057789 165.02782 \nL 204.630866 164.821693 \nL 204.480415 164.804755 \nL 205.409561 165.490708 \nL 206.648441 166.357473 \nL 207.010188 166.647865 \nL 206.459278 166.363464 \nL 206.060716 166.181805 \nL 206.522162 166.526652 \nL 207.279812 167.0395 \nL 207.264767 167.085023 \nL 206.326061 166.595891 \nL 205.464524 166.166374 \nL 205.523572 166.268125 \nL 205.996408 166.597375 \nL 205.600267 166.444703 \nL 204.024176 165.664926 \nL 202.520083 164.948732 \nL 202.301819 164.925627 \nL 202.740065 165.24172 \nL 201.995574 164.954006 \nL 199.572578 163.845159 \nL 197.29707 162.846427 \nL 196.9667 162.817003 \nL 197.639921 163.265936 \nL 196.602109 162.909035 \nL 193.166981 161.473133 \nL 190.035368 160.226024 \nL 189.769155 160.290239 \nL 190.934049 160.977805 \nL 189.664344 160.610068 \nL 185.092243 158.879788 \nL 181.056985 157.438133 \nL 181.027792 157.670884 \nL 182.915624 158.661256 \nL 181.479997 158.332329 \nL 175.694692 156.367513 \nL 170.753931 154.802294 \nL 171.132997 155.255541 \nL 173.949559 156.576187 \nL 172.427235 156.329688 \nL 165.419841 154.216218 \nL 159.63211 152.613655 \nL 160.587848 153.316652 \nL 164.502733 154.959037 \nL 162.985137 154.830307 \nL 154.820826 152.672212 \nL 148.299347 151.123328 \nL 149.972727 152.076098 \nL 155.091768 153.993293 \nL 153.659432 154.001556 \nL 144.448525 151.90319 \nL 137.322576 150.486741 \nL 139.789411 151.655217 \nL 146.126723 153.764874 \nL 144.815158 153.907671 \nL 134.656949 151.955876 \nL 127.013944 150.724922 \nL 130.26293 152.0472 \nL 137.744472 154.246926 \nL 136.523186 154.504078 \nL 125.451501 152.761294 \nL 117.299397 151.744475 \nL 121.250939 153.148854 \nL 129.758465 155.338405 \nL 128.545558 155.685705 \nL 116.513489 154.198754 \nL 107.790617 153.415021 \nL 112.354817 154.840033 \nL 121.795238 156.938771 \nL 120.504226 157.362626 \nL 107.424292 156.180096 \nL 98.059845 155.656575 \nL 103.205687 157.060689 \nL 113.567963 159.010077 \nL 112.165886 159.51371 \nL 97.995475 158.699355 \nL 87.995584 158.479375 \nL 93.792782 159.834568 \nL 105.158999 161.585508 \nL 103.709662 162.182715 \nL 88.541197 161.813419 \nL 78.058117 161.947695 \nL 84.665459 163.221582 \nL 97.157659 164.715555 \nL 95.822524 165.414802 \nL 79.933828 165.561847 \nL 69.274993 166.08625 \nL 76.866164 167.225042 \nL 90.552032 168.383711 \nL 89.533602 169.172165 \nL 73.359236 169.875016 \nL 62.927213 170.788573 \nz\n\" style=\"fill:#00ffff;stroke:#00ffff;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 70.841568 333.36 \nL 70.841568 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m7c260c1000\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"70.841568\" xlink:href=\"#m7c260c1000\" y=\"333.36\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(60.289224 347.958438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 142.206277 333.36 \nL 142.206277 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"142.206277\" xlink:href=\"#m7c260c1000\" y=\"333.36\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(134.835184 347.958438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 213.570987 333.36 \nL 213.570987 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"213.570987\" xlink:href=\"#m7c260c1000\" y=\"333.36\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0 -->\n      <g transform=\"translate(210.389737 347.958438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 284.935696 333.36 \nL 284.935696 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"284.935696\" xlink:href=\"#m7c260c1000\" y=\"333.36\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 5 -->\n      <g transform=\"translate(281.754446 347.958438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 356.300406 333.36 \nL 356.300406 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"356.300406\" xlink:href=\"#m7c260c1000\" y=\"333.36\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 10 -->\n      <g transform=\"translate(349.937906 347.958438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 44.845313 318.646111 \nL 379.645313 318.646111 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m95125a27eb\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m95125a27eb\" y=\"318.646111\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 322.44533)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 44.845313 281.681723 \nL 379.645313 281.681723 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m95125a27eb\" y=\"281.681723\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 7.5 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(13.5625 285.480942)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 44.845313 244.717335 \nL 379.645313 244.717335 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m95125a27eb\" y=\"244.717335\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5.0 -->\n      <g transform=\"translate(13.5625 248.516554)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 44.845313 207.752947 \nL 379.645313 207.752947 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m95125a27eb\" y=\"207.752947\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2.5 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(13.5625 211.552166)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 44.845313 170.788559 \nL 379.645313 170.788559 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m95125a27eb\" y=\"170.788559\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.0 -->\n      <g transform=\"translate(21.942188 174.587778)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 44.845313 133.824171 \nL 379.645313 133.824171 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m95125a27eb\" y=\"133.824171\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2.5 -->\n      <g transform=\"translate(21.942188 137.62339)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 44.845313 96.859783 \nL 379.645313 96.859783 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m95125a27eb\" y=\"96.859783\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 5.0 -->\n      <g transform=\"translate(21.942188 100.659002)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 44.845313 59.895396 \nL 379.645313 59.895396 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m95125a27eb\" y=\"59.895396\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 7.5 -->\n      <g transform=\"translate(21.942188 63.694614)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_27\">\n      <path clip-path=\"url(#p77ba37f7e5)\" d=\"M 44.845313 22.931008 \nL 379.645313 22.931008 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m95125a27eb\" y=\"22.931008\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 10.0 -->\n      <g transform=\"translate(15.579688 26.730226)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 44.845313 333.36 \nL 44.845313 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 379.645313 333.36 \nL 379.645313 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 44.845313 333.36 \nL 379.645313 333.36 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 44.845313 7.2 \nL 379.645313 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p77ba37f7e5\">\n   <rect height=\"326.16\" width=\"334.8\" x=\"44.845313\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": "<Figure size 432x432 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "theta = torch.linspace(-np.pi, np.pi, steps=1000)\n",
        "\n",
        "# compute rho(theta) as per formula above\n",
        "rho = (1 + .9 * torch.cos(6*theta))\\\n",
        "      * (1 + .01 * torch.cos(24*theta))\\\n",
        "      * (.5 + .05* torch.cos(200*theta))\\\n",
        "      * (10 + torch.sin(10*theta))\n",
        "### YOUR CODE HERE\n",
        "\n",
        "# Now convert polar (rho, theta) pairs into cartesian (x,y) to plot them.\n",
        "x = rho*torch.cos(theta)### YOUR CODE HERE\n",
        "y = rho*torch.sin(theta)### YOUR CODE HERE\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.fill(x.numpy(), y.numpy(), color='aqua')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "uiqu5Pddky3e"
      },
      "outputs": [],
      "source": [
        "### Task 2: Using the Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !wget https://raw.githubusercontent.com/neychev/harbour_ml2020/master/day10_Optimization_and_regularization_in_DL/notmnist.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Parsing...\nfound broken img: ./notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png [it's ok if <10 images are broken]\nfound broken img: ./notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png [it's ok if <10 images are broken]\nDone\n"
        }
      ],
      "source": [
        "from notmnist import load_notmnist\n",
        "X_train, y_train, X_test, y_test = load_notmnist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DatasetMNIST(Dataset):\n",
        "    def __init__(self, path='./notMNIST_small', letters='ABCDEFGHIJ', transform=None):\n",
        "        self.data, self.labels, _ ,_  = load_notmnist(path=path, letters=letters, test_size=0)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # load image as ndarray type (Height * Width * Channels)\n",
        "        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n",
        "        # in this example, i don't use ToTensor() method of torchvision.transforms\n",
        "        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n",
        "        image = self.data[index].transpose(1, 2, 0)\n",
        "        label = self.labels[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Parsing...\nfound broken img: ./notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png [it's ok if <10 images are broken]\nDone\n"
        }
      ],
      "source": [
        "full_dataset = DatasetMNIST('./notMNIST_small', 'AB', transform=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "(28, 28, 1)\n<class 'numpy.ndarray'>\n"
        }
      ],
      "source": [
        "# we can access and get data with index by __getitem__(index)\n",
        "img, lab = full_dataset.__getitem__(0)\n",
        "\n",
        "print(img.shape)\n",
        "print(type(img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "torch.Size([1, 28, 28])"
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torchvision.transforms.ToTensor()\n",
        "\n",
        "\"\"\" \n",
        "    >>> torchvision.transforms.ToTensor() converts a PIL image or nd-array to tensor\n",
        "\"\"\"\n",
        "\n",
        "a(img).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"198.378068pt\" version=\"1.1\" viewBox=\"0 0 368.925 198.378068\" width=\"368.925pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 198.378068 \nL 368.925 198.378068 \nL 368.925 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 174.499943 \nL 179.106818 174.499943 \nL 179.106818 22.318125 \nL 26.925 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p4a8c60167f)\">\n    <image height=\"153\" id=\"image7dfbbb8310\" transform=\"scale(1 -1)translate(0 -153)\" width=\"153\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-21.499943\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m13fabecd04\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.642532\" xlink:href=\"#m13fabecd04\" y=\"174.499943\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(26.461282 189.098381)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"83.993182\" xlink:href=\"#m13fabecd04\" y=\"174.499943\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(77.630682 189.098381)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"138.343831\" xlink:href=\"#m13fabecd04\" y=\"174.499943\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(131.981331 189.098381)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_4\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m4b8407a11c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4b8407a11c\" y=\"25.035657\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 28.834876)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4b8407a11c\" y=\"52.210982\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(13.5625 56.010201)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4b8407a11c\" y=\"79.386307\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 83.185526)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4b8407a11c\" y=\"106.561631\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 110.36085)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4b8407a11c\" y=\"133.736956\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 137.536175)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4b8407a11c\" y=\"160.912281\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 164.7115)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 174.499943 \nL 26.925 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 179.106818 174.499943 \nL 179.106818 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 174.499943 \nL 179.106818 174.499943 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 22.318125 \nL 179.106818 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_10\">\n    <!-- 1 -->\n    <g transform=\"translate(99.198409 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-49\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path d=\"M 209.543182 174.499943 \nL 361.725 174.499943 \nL 361.725 22.318125 \nL 209.543182 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pb3c3a262d0)\">\n    <image height=\"153\" id=\"image16d3c45fa4\" transform=\"scale(1 -1)translate(0 -153)\" width=\"153\" x=\"209.543182\" xlink:href=\"data:image/png;base64,\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\" y=\"-21.499943\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"212.260714\" xlink:href=\"#m13fabecd04\" y=\"174.499943\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0 -->\n      <g transform=\"translate(209.079464 189.098381)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"266.611364\" xlink:href=\"#m13fabecd04\" y=\"174.499943\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 10 -->\n      <g transform=\"translate(260.248864 189.098381)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"320.962013\" xlink:href=\"#m13fabecd04\" y=\"174.499943\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 20 -->\n      <g transform=\"translate(314.599513 189.098381)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m4b8407a11c\" y=\"25.035657\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0 -->\n      <g transform=\"translate(196.180682 28.834876)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m4b8407a11c\" y=\"52.210982\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 5 -->\n      <g transform=\"translate(196.180682 56.010201)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m4b8407a11c\" y=\"79.386307\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 10 -->\n      <g transform=\"translate(189.818182 83.185526)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m4b8407a11c\" y=\"106.561631\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 15 -->\n      <g transform=\"translate(189.818182 110.36085)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m4b8407a11c\" y=\"133.736956\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 20 -->\n      <g transform=\"translate(189.818182 137.536175)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m4b8407a11c\" y=\"160.912281\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 25 -->\n      <g transform=\"translate(189.818182 164.7115)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 209.543182 174.499943 \nL 209.543182 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 361.725 174.499943 \nL 361.725 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 209.543182 174.499943 \nL 361.725 174.499943 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 209.543182 22.318125 \nL 361.725 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_20\">\n    <!-- 0 -->\n    <g transform=\"translate(281.816591 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-48\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p4a8c60167f\">\n   <rect height=\"152.181818\" width=\"152.181818\" x=\"26.925\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"pb3c3a262d0\">\n   <rect height=\"152.181818\" width=\"152.181818\" x=\"209.543182\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": "<Figure size 432x288 with 2 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "inds = np.random.randint(len(full_dataset), size=2)\n",
        "\n",
        "for i in range(2):\n",
        "    plt.subplot(1, 2, i + 1)\n",
        "    plt.imshow(full_dataset[inds[i]][0].reshape([28,28]))\n",
        "    plt.title(str(full_dataset[inds[i]][1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "D7ijdIX_ky5A"
      },
      "outputs": [],
      "source": [
        "#### To the DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = DataLoader(full_dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "uMpT8CCPky5P"
      },
      "outputs": [],
      "source": [
        "We can use dataloader as iterator by using iter() function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n"
        }
      ],
      "source": [
        "train_iter = iter(train_loader)\n",
        "print(type(train_iter))"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "rxrGNwQHky5b"
      },
      "outputs": [],
      "source": [
        "We can look at images and labels of batch size by extracting data `.next()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "images shape on batch size = torch.Size([8, 28, 28, 1])\nlabels shape on batch size = torch.Size([8])\n"
        }
      ],
      "source": [
        "images, labels = train_iter.next()\n",
        "\n",
        "print('images shape on batch size = {}'.format(images.size()))\n",
        "print('labels shape on batch size = {}'.format(labels.size()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
        },
        {
          "data": {
            "image/png": "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\n",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"73.789199pt\" version=\"1.1\" viewBox=\"0 0 349.2 73.789199\" width=\"349.2pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 73.789199 \nL 349.2 73.789199 \nL 349.2 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g clip-path=\"url(#pb00f74fd48)\">\n    <image height=\"45\" id=\"imagea17ead14d3\" transform=\"scale(1 -1)translate(0 -45)\" width=\"335\" x=\"7.2\" xlink:href=\"data:image/png;base64,\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\" y=\"-21.589199\"/>\n   </g>\n   <g id=\"text_1\">\n    <!-- [0 0 1 0 1 1 0 1] -->\n    <defs>\n     <path d=\"M 8.59375 75.984375 \nL 29.296875 75.984375 \nL 29.296875 69 \nL 17.578125 69 \nL 17.578125 -6.203125 \nL 29.296875 -6.203125 \nL 29.296875 -13.1875 \nL 8.59375 -13.1875 \nz\n\" id=\"DejaVuSans-91\"/>\n     <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n     <path id=\"DejaVuSans-32\"/>\n     <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n     <path d=\"M 30.421875 75.984375 \nL 30.421875 -13.1875 \nL 9.71875 -13.1875 \nL 9.71875 -6.203125 \nL 21.390625 -6.203125 \nL 21.390625 69 \nL 9.71875 69 \nL 9.71875 75.984375 \nz\n\" id=\"DejaVuSans-93\"/>\n    </defs>\n    <g transform=\"translate(126.03 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-91\"/>\n     <use x=\"39.013672\" xlink:href=\"#DejaVuSans-48\"/>\n     <use x=\"102.636719\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"134.423828\" xlink:href=\"#DejaVuSans-48\"/>\n     <use x=\"198.046875\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"229.833984\" xlink:href=\"#DejaVuSans-49\"/>\n     <use x=\"293.457031\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"325.244141\" xlink:href=\"#DejaVuSans-48\"/>\n     <use x=\"388.867188\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"420.654297\" xlink:href=\"#DejaVuSans-49\"/>\n     <use x=\"484.277344\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"516.064453\" xlink:href=\"#DejaVuSans-49\"/>\n     <use x=\"579.6875\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"611.474609\" xlink:href=\"#DejaVuSans-48\"/>\n     <use x=\"675.097656\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"706.884766\" xlink:href=\"#DejaVuSans-49\"/>\n     <use x=\"770.507812\" xlink:href=\"#DejaVuSans-93\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pb00f74fd48\">\n   <rect height=\"44.271074\" width=\"334.8\" x=\"7.2\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# make grid takes tensor as arg\n",
        "# tensor : (batchsize, channels, height, width)\n",
        "grid = torchvision.utils.make_grid(images.permute([0, 3, 1, 2]))\n",
        "\n",
        "plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
        "plt.axis('off')\n",
        "plt.title(labels.numpy());"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "_UpAdDPYky5v"
      },
      "outputs": [],
      "source": [
        "And now with transformations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Parsing...\nfound broken img: ./notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png [it's ok if <10 images are broken]\nfound broken img: ./notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png [it's ok if <10 images are broken]\nDone\n"
        }
      ],
      "source": [
        "train_dataset_with_transform = DatasetMNIST(\n",
        "    transform=torchvision.transforms.ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "image shape at the first row : torch.Size([1, 28, 28])\n"
        }
      ],
      "source": [
        "img, lab = train_dataset_with_transform.__getitem__(0)\n",
        "\n",
        "print('image shape at the first row : {}'.format(img.size()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\nimages shape on batch size = torch.Size([8, 1, 28, 28])\nlabels shape on batch size = torch.Size([8])\n"
        }
      ],
      "source": [
        "train_loader_tr = DataLoader(train_dataset_with_transform, batch_size=8, shuffle=True)\n",
        "\n",
        "train_iter_tr = iter(train_loader_tr)\n",
        "print(type(train_iter_tr))\n",
        "\n",
        "images, labels = train_iter_tr.next()\n",
        "\n",
        "print('images shape on batch size = {}'.format(images.size()))\n",
        "print('labels shape on batch size = {}'.format(labels.size()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
        },
        {
          "data": {
            "image/png": "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\n",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"73.789199pt\" version=\"1.1\" viewBox=\"0 0 349.2 73.789199\" width=\"349.2pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 73.789199 \nL 349.2 73.789199 \nL 349.2 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g clip-path=\"url(#p1af8d9e1ad)\">\n    <image height=\"45\" id=\"image199ffb0bdf\" transform=\"scale(1 -1)translate(0 -45)\" width=\"335\" x=\"7.2\" xlink:href=\"data:image/png;base64,\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\" y=\"-21.589199\"/>\n   </g>\n   <g id=\"text_1\">\n    <!-- [1 6 7 1 7 9 7 5] -->\n    <defs>\n     <path d=\"M 8.59375 75.984375 \nL 29.296875 75.984375 \nL 29.296875 69 \nL 17.578125 69 \nL 17.578125 -6.203125 \nL 29.296875 -6.203125 \nL 29.296875 -13.1875 \nL 8.59375 -13.1875 \nz\n\" id=\"DejaVuSans-91\"/>\n     <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n     <path id=\"DejaVuSans-32\"/>\n     <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n     <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n     <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n     <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n     <path d=\"M 30.421875 75.984375 \nL 30.421875 -13.1875 \nL 9.71875 -13.1875 \nL 9.71875 -6.203125 \nL 21.390625 -6.203125 \nL 21.390625 69 \nL 9.71875 69 \nL 9.71875 75.984375 \nz\n\" id=\"DejaVuSans-93\"/>\n    </defs>\n    <g transform=\"translate(126.03 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-91\"/>\n     <use x=\"39.013672\" xlink:href=\"#DejaVuSans-49\"/>\n     <use x=\"102.636719\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"134.423828\" xlink:href=\"#DejaVuSans-54\"/>\n     <use x=\"198.046875\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"229.833984\" xlink:href=\"#DejaVuSans-55\"/>\n     <use x=\"293.457031\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"325.244141\" xlink:href=\"#DejaVuSans-49\"/>\n     <use x=\"388.867188\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"420.654297\" xlink:href=\"#DejaVuSans-55\"/>\n     <use x=\"484.277344\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"516.064453\" xlink:href=\"#DejaVuSans-57\"/>\n     <use x=\"579.6875\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"611.474609\" xlink:href=\"#DejaVuSans-55\"/>\n     <use x=\"675.097656\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"706.884766\" xlink:href=\"#DejaVuSans-53\"/>\n     <use x=\"770.507812\" xlink:href=\"#DejaVuSans-93\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p1af8d9e1ad\">\n   <rect height=\"44.271074\" width=\"334.8\" x=\"7.2\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
        "plt.axis('off')\n",
        "plt.title(labels.numpy());"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "bBOzOoW7ky6S"
      },
      "outputs": [],
      "source": [
        "### Composing several transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "yD4PIU_cky6W"
      },
      "outputs": [],
      "source": [
        "If you want to take data augmentation, you have to make List using `torchvision.transforms.Compose`\n",
        "\n",
        "```\n",
        "class Compose(object):\n",
        "    \"\"\"Composes several transforms together.\n",
        "    Args:\n",
        "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
        "    Example:\n",
        "        >>> transforms.Compose([\n",
        "        >>>     transforms.CenterCrop(10),\n",
        "        >>>     transforms.ToTensor(),\n",
        "        >>> ])\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, img):\n",
        "        for t in self.transforms:\n",
        "            img = t(img)\n",
        "        return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        format_string = self.__class__.__name__ + '('\n",
        "        for t in self.transforms:\n",
        "            format_string += '\\n'\n",
        "            format_string += '    {0}'.format(t)\n",
        "        format_string += '\\n)'\n",
        "        return format_string\n",
        "```\n",
        "\n",
        "\n",
        "this function can convert some image by order within `__call__` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Flatten():\n",
        "    def __call__(self, pic):\n",
        "        return pic.flatten()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '()'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-27f3133d3ad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \"\"\"\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_is_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pic should be PIL Image or ndarray. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_numpy_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
          ]
        }
      ],
      "source": [
        "a(img).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = Flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "torch.Size([784])"
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a(img).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_transform = torchvision.transforms.Compose([\n",
        "                                                torchvision.transforms.ToTensor(),\n",
        "                                                Flatten()\n",
        "                                              ])"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "4a-9L11Pky65"
      },
      "outputs": [],
      "source": [
        "# Putting all together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "device(type='cpu')"
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use GPU if available\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "def subset_ind(dataset, ratio: float):\n",
        "    \"\"\" \n",
        "        >>> np.random.choice(array, size, replacement(boolean)) get random samples from an array of size n with or without replacement  \n",
        "    \"\"\"\n",
        "    return np.random.choice(len(dataset), int(ratio * len(dataset)), replace = False) ### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Parsing...\nfound broken img: ./notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png [it's ok if <10 images are broken]\nfound broken img: ./notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png [it's ok if <10 images are broken]\nDone\n\n\n dataset size: 2808, labels: [0 1 2 3 4 5 6 7 8 9]\n"
        }
      ],
      "source": [
        "dataset = DatasetMNIST(\n",
        "    './notMNIST_small',\n",
        "#     'AB',\n",
        "    transform = new_transform\n",
        ")\n",
        "\n",
        "shrink_inds = subset_ind(dataset, 0.15)\n",
        "dataset = Subset(dataset, shrink_inds)\n",
        "\n",
        "print(f'\\n\\n dataset size: {len(dataset)}, labels: {np.unique(dataset.dataset.labels)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "training size: 2247\nvalidation size: 561\n"
        }
      ],
      "source": [
        "val_size = 0.2\n",
        "val_inds = subset_ind(dataset, val_size)\n",
        "\n",
        "train_dataset = Subset(dataset, [i for i in range(len(dataset)) if i not in val_inds])\n",
        "val_dataset = Subset(dataset, val_inds)\n",
        "\n",
        "print(f'  training size: {len(train_dataset)}\\nvalidation size: {len(val_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\nimages shape on batch size = torch.Size([32, 784])\nlabels shape on batch size = torch.Size([32])\n"
        }
      ],
      "source": [
        "train_iter = iter(train_loader)\n",
        "print(type(train_iter))\n",
        "\n",
        "images, labels = train_iter.next()\n",
        "\n",
        "print('images shape on batch size = {}'.format(images.size()))\n",
        "print('labels shape on batch size = {}'.format(labels.size()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create network again just in case\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(784, 10),\n",
        "    nn.Sigmoid(),\n",
        ")\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, loss_fn, opt, n_epochs: int):\n",
        "    '''\n",
        "        <<< model >>> neural network model we created,\n",
        "        <<< train_loader, val_loader >>> train and validation set\n",
        "        <<< loss_fn >>> our loss function (we have worked with crossEntropyLoss and NNLLLoss)\n",
        "        <<< opt >>> optimizer (in our case Adam. It could be a multiple others like SGD, AdaBoost ...)\n",
        "        <<< n_epochs >>> number of iterations\n",
        "    '''\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "    val_accuracy = []\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        ep_train_loss = []\n",
        "        ep_val_loss = []\n",
        "        ep_val_accuracy = []\n",
        "        start_time = time.time()\n",
        "\n",
        "        model.train(True) \n",
        "        \"\"\" \n",
        "            >>> Model.train(True) ==> enables DropOut ; a batch normalization technique\n",
        "            >>> DropOut is a batch normalizations technique which helps us minimize the chance of overfitting by arbitarily removing features during the training phase \n",
        "        \"\"\"\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            print('Train_loader', len(X_batch), len(y_batch))\n",
        "            predict = model(X_batch) # ==> Basically fitting our data to the model\n",
        "\n",
        "            loss = loss_fn(predict, y_batch) # ==> Calculate the loss for this batch\n",
        "\n",
        "            loss.backward() #==> Compute the gradient >>> Back_propagation ie Chain rule\n",
        "            opt.step() # ==> We want tot optimize our gradients \n",
        "            opt.zero_grad() # ==> Clear the gradients\n",
        "\n",
        "            \"\"\"\n",
        "                    *** Training *** To_Do\n",
        "                    === === === === === ===\n",
        "                >>> Enable dropout to reduce chances of overvitting the training data    \n",
        "                >>> Train on batch using the predict function\n",
        "                >>> Compute the loss\n",
        "                >>> Calculate the gradients\n",
        "                >>> Optimize the gradient\n",
        "                >>> Clear storage because our otimizer holds results\n",
        "            \"\"\"\n",
        "\n",
        "            ep_train_loss.append(loss.item()) #Incase u have an error remove the item() part\n",
        "\n",
        "        model.train(False) # disable dropout / use averages for batch_norm\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                predict_1 = model(X_batch)\n",
        "                loss_1 = loss_fn(predict_1, y_batch)\n",
        "                \n",
        "                ep_val_loss.append(loss_1)### YOUR CODE HERE)\n",
        "                y_pred = predict_1.max(1)[1].data  ### YOUR CODE HERE\n",
        "                ep_val_accuracy.append((y_pred == y_batch).to(torch.float32).mean().item())### YOUR CODE HERE)\n",
        "\n",
        "                \"\"\" \n",
        "                    *** Validation *** To_Do\n",
        "                    === === === === === === ===\n",
        "                    >>> Start by disabling dropout\n",
        "                    >>> No need to calculate the gradients because with validation set we dont have to optimize the gradients\n",
        "                    >>> fit the data to our model\n",
        "                    >>> calculate our loss\n",
        "                    >>> test the model ie prediction.max(1)[1].data\n",
        "                    >>> calculate the accuracy of the model\n",
        "                \"\"\"\n",
        "\n",
        "        # print the results for this epoch:\n",
        "        print(f'Epoch {epoch + 1} of {n_epochs} took {time.time() - start_time:.3f}s')\n",
        "\n",
        "        train_loss.append(np.mean(ep_train_loss))\n",
        "        val_loss.append(np.mean(ep_val_loss))\n",
        "        val_accuracy.append(np.mean(ep_val_accuracy))\n",
        "        \n",
        "        print(f\"\\t  training loss: {train_loss[-1]:.6f}\")\n",
        "        print(f\"\\tvalidation loss: {val_loss[-1]:.6f}\")\n",
        "        print(f\"\\tvalidation accuracy: {val_accuracy[-1]:.3f}\")\n",
        "\n",
        "    return train_loss, val_loss, val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 7 7\nEpoch 6 of 30 took 1.655s\n\t  training loss: 2.299644\n\tvalidation loss: 2.296981\n\tvalidation accuracy: 0.088\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 7 7\nEpoch 7 of 30 took 1.719s\n\t  training loss: 2.298214\n\tvalidation loss: 2.297702\n\tvalidation accuracy: 0.099\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 7 7\nEpoch 8 of 30 took 1.843s\n\t  training loss: 2.299495\n\tvalidation loss: 2.297580\n\tvalidation accuracy: 0.097\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 7 7\nEpoch 9 of 30 took 1.873s\n\t  training loss: 2.297648\n\tvalidation loss: 2.296607\n\tvalidation accuracy: 0.099\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 7 7\nEpoch 10 of 30 took 1.632s\n\t  training loss: 2.299096\n\tvalidation loss: 2.297079\n\tvalidation accuracy: 0.100\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 7 7\nEpoch 11 of 30 took 1.723s\n\t  training loss: 2.298778\n\tvalidation loss: 2.296759\n\tvalidation accuracy: 0.088\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 7 7\nEpoch 12 of 30 took 1.350s\n\t  training loss: 2.299474\n\tvalidation loss: 2.298091\n\tvalidation accuracy: 0.101\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 7 7\nEpoch 13 of 30 took 1.572s\n\t  training loss: 2.299372\n\tvalidation loss: 2.297954\n\tvalidation accuracy: 0.102\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 7 7\nEpoch 14 of 30 took 1.590s\n\t  training loss: 2.298683\n\tvalidation loss: 2.296412\n\tvalidation accuracy: 0.099\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 7 7\nEpoch 15 of 30 took 1.494s\n\t  training loss: 2.299150\n\tvalidation loss: 2.297502\n\tvalidation accuracy: 0.097\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 7 7\nEpoch 16 of 30 took 1.637s\n\t  training loss: 2.298736\n\tvalidation loss: 2.297729\n\tvalidation accuracy: 0.090\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 7 7\nEpoch 17 of 30 took 1.627s\n\t  training loss: 2.298376\n\tvalidation loss: 2.296663\n\tvalidation accuracy: 0.104\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 7 7\nEpoch 18 of 30 took 1.920s\n\t  training loss: 2.298750\n\tvalidation loss: 2.296477\n\tvalidation accuracy: 0.105\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 7 7\nEpoch 19 of 30 took 1.741s\n\t  training loss: 2.298193\n\tvalidation loss: 2.297526\n\tvalidation accuracy: 0.097\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\nTrain_loader 32 32\n"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-155891ea3657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-101-a5576f648a82>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, loss_fn, opt, n_epochs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train_loader'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ==> Basically fitting our data to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ==> Calculate the loss for this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m     )\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "n_epochs = 30\n",
        "\n",
        "train_loss, val_loss, val_accuracy = train_model(model, train_loader, val_loader, loss_function, opt, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_train_process(train_loss, val_loss, val_accuracy):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    axes[0].set_title('Loss')\n",
        "    axes[0].plot(train_loss, label='train')\n",
        "    axes[0].plot(val_loss, label='validation')\n",
        "    axes[0].legend()\n",
        "\n",
        "    axes[1].set_title('Validation accuracy')\n",
        "    axes[1].plot(val_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_train_process(train_loss, val_loss, val_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "R-Kg1vDYky8D"
      },
      "outputs": [],
      "source": [
        "## Real network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create network again just in case\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(784, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(500, 200),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(200, 10),\n",
        "    nn.Sigmoid(),\n",
        ") # This dense network has 784 inputs and 10 outputs --> think multiclass classification problem\n",
        "model.to(device, torch.float32)\n",
        "\n",
        "# opt = torch.optim.ASGD(model.parameters(), lr=3e-4)\n",
        "opt = torch.optim.Adamax(model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_epochs = 30\n",
        "\n",
        "train_loss, val_loss, val_accuracy = train_model(model, train_loader, val_loader, loss_func, opt, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_train_process(train_loss, val_loss, val_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "ltEjY4dIky8Y"
      },
      "outputs": [],
      "source": [
        "## Overfit!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create network again just in case\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(784, 600),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(600, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(500, 400),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(400, 200),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(200, 10),\n",
        "    nn.Sigmoid(),\n",
        ")\n",
        "\n",
        "opt = torch.optim.Adamax(model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_epochs = 30\n",
        "\n",
        "train_loss, val_loss, val_accuracy = train_model(model, train_loader, val_loader, loss_func, opt, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_train_process(train_loss, val_loss, val_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "NPx9YsBKky8t"
      },
      "outputs": [],
      "source": [
        "## Your turn\n",
        "Try to add some additional transformations (e.g. random crop, rotation etc.) and train your model!"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "dzLyDywKky8t"
      },
      "outputs": [],
      "source": [
        "### Dropout try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(784, 600),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(),\n",
        "    nn.Linear(600, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(500, 400),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(),\n",
        "    nn.Linear(400, 200),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(200, 10),\n",
        "    nn.Sigmoid(),\n",
        ")\n",
        "\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_epochs = 30\n",
        "\n",
        "train_loss, val_loss, val_accuracy = train_model(model, train_loader, val_loader, loss_func, opt, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_train_process(train_loss, val_loss, val_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "ABO-iRPIky8y"
      },
      "outputs": [],
      "source": [
        "### Batchnorm try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(784, 600),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(600),\n",
        "    nn.Linear(600, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(500, 400),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(400),\n",
        "    nn.Linear(400, 200),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(200, 10),\n",
        "    nn.Sigmoid(),\n",
        ")\n",
        "\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_epochs = 30\n",
        "\n",
        "train_loss, val_loss, val_accuracy = train_model(model, train_loader, val_loader, loss_func, opt, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_train_process(train_loss, val_loss, val_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "M8pFTKUjky85"
      },
      "outputs": [],
      "source": [
        "### 3. Save the model (model checkpointing)\n",
        "\n",
        "Now we have trained a model! Obviously we do not want to retrain the model everytime we want to use it. Plus if you are training a super big model, you probably want to save checkpoint periodically so that you can always fall back to the last checkpoint in case something bad happened or you simply want to test models at different training iterations.\n",
        "\n",
        "Model checkpointing is fairly simple in PyTorch. First, we define a helper function that can save a model to the disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_checkpoint(checkpoint_path, model, optimizer):\n",
        "    # state_dict: a Python dictionary object that:\n",
        "    # - for a model, maps each layer to its parameter tensor;\n",
        "    # - for an optimizer, contains info about the optimizers states and hyperparameters used.\n",
        "    state = {\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer' : optimizer.state_dict()}\n",
        "    torch.save(state, checkpoint_path)\n",
        "    print('model saved to %s' % checkpoint_path)\n",
        "    \n",
        "def load_checkpoint(checkpoint_path, model, optimizer):\n",
        "    state = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(state['state_dict'])\n",
        "    optimizer.load_state_dict(state['optimizer'])\n",
        "    print('model loaded from %s' % checkpoint_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model(model,val_loader, loss_fn, opt, n_epochs: int):\n",
        "    val_loss = []\n",
        "    val_accuracy = []\n",
        "    for epoch in range(n_epochs):\n",
        "        ep_val_loss = []\n",
        "        ep_val_accuracy = []\n",
        "        start_time = time.time()\n",
        "        model.train(False) # disable dropout / use averages for batch_norm\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                predict_1 = model(X_batch)\n",
        "                loss_1 = loss_fn(predict_1, y_batch)\n",
        "                \n",
        "                ep_val_loss.append(loss_1)\n",
        "                y_pred = predict_1.max(1)[1].data\n",
        "                ep_val_accuracy.append((y_pred == y_batch).to(torch.float32).mean().item())\n",
        "        \n",
        "        print(f'Epoch {epoch + 1} of {n_epochs} took {time.time() - start_time:.3f}s')\n",
        "\n",
        "        val_loss.append(np.mean(ep_val_loss))\n",
        "        val_accuracy.append(np.mean(ep_val_accuracy))\n",
        "        \n",
        "        print(f\"\\t  training loss: {train_loss[-1]:.6f}\")\n",
        "        print(f\"\\tvalidation loss: {val_loss[-1]:.6f}\")\n",
        "        print(f\"\\tvalidation accuracy: {val_accuracy[-1]:.3f}\")\n",
        "\n",
        "    return val_loss, val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "\n",
        "# create a brand new model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(784, 600),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(600),\n",
        "    nn.Linear(600, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(500, 400),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(400),\n",
        "    nn.Linear(400, 200),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(200, 10),\n",
        "    nn.Sigmoid(),\n",
        ")\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "# Testing -- you should get a pretty poor performance since the model hasn't learned anything yet.\n",
        "n_epochs = 30\n",
        "loss, accuracy = test_model(model, val_loader,loss_function, optimizer, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_test_process(val_loss, val_accuracy):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    axes[0].set_title('Loss')\n",
        "    axes[0].plot(val_loss, label='validation')\n",
        "    axes[0].legend()\n",
        "\n",
        "    axes[1].set_title('Validation accuracy')\n",
        "    axes[1].plot(val_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_test_process(loss, accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "WRC6w4iFky9E"
      },
      "outputs": [],
      "source": [
        "#### Define a training loop with model checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_save(epoch, save_interval, log_interval=100):\n",
        "    model.train(True)  # set training mode\n",
        "    iteration = 0\n",
        "    for ep in range(epoch):\n",
        "        for batch_idx, (data, target) in enumerate(trainset_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if iteration % log_interval == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
        "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
        "            # different from before: saving model checkpoints\n",
        "            if iteration % save_interval == 0 and iteration > 0:\n",
        "                save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)\n",
        "            iteration += 1\n",
        "        test()\n",
        "    \n",
        "    # save the final model\n",
        "    save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_save(5, save_interval=500, log_interval=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a new model\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "# load from the final checkpoint\n",
        "load_checkpoint('mnist-4690.pth', model, optimizer)\n",
        "# should give you the final model accuracy\n",
        "test()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "WSHdfDZwky9S"
      },
      "outputs": [],
      "source": [
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "### More about pytorch:\n",
        "* Using torch on GPU and multi-GPU - [link](http://pytorch.org/docs/master/notes/cuda.html)\n",
        "* More tutorials on pytorch - [link](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
        "* Pytorch examples - a repo that implements many cool DL models in pytorch - [link](https://github.com/pytorch/examples)\n",
        "* Practical pytorch - a repo that implements some... other cool DL models... yes, in pytorch - [link](https://github.com/spro/practical-pytorch)\n",
        "* And some more - [link](https://www.reddit.com/r/pytorch/comments/6z0yeo/pytorch_and_pytorch_tricks_for_kaggle/)"
      ]
    }
  ]
}